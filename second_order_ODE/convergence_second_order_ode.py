import numpy as np
import cvxpy as cp
import matplotlib.pyplot as plt


def compute_convergence_guarantee(mu, alpha, beta, a=None, P=None, psd=False, upper=2., lower=0., epsilon=10 ** -5, verbose=False):
    """
    Consider the second-order gradient flow
            d^2x/dt2 + beta * dx/dt + alpha * grad f(x(t)) = 0,
    where alpha, beta are positive parameters, and f are mu-strongly convex functions.

    We consider quadratic Lyapunov functions
        V(x(t)) = a(f(x(t)) - f_*) + X^TPX,
        X = (x(t)-x^*, dx/dt),
    where a is a positive parameter, and P is a symmetric matrix, such that V(x(t)) is positive over the trajectory.

    This code computes the worst-case guarantee tau(mu, a, alpha, beta, P) such that,
        d/dt V(x(t)) <= -tau(mu, a, alpha, beta, P) V(x(t)),
    for all L-smooth and mu-strongly convex functions, and all ODEs generated by the second-order gradient flow.

    When P=None, this code optimizes over the family of quadratic Lyapunov function.

    :param mu: strong convexity assumption
    :param alpha: ode parameter
    :param beta: ode parameter
    :param a: lyapunov parameter (one has to be fixed)
    :param P: lyapunov parameter matrix - is optimized when equal to None
    :param psd: P must be psd when set to True, relaxed otherwise.
    :param upper: upper bound on the convergence rate
    :param lower: lower bound on the convergence rate
    :param epsilon: precision
    :return:
            - worst-case guarantee tau(L, mu, alpha, beta, P)
            - P
            - dual variables associated with interpolation inequalities (decreasing derivatives)
            - dual variables associated with positivy constraints

    """

    if P is None or a is None:
        P_ = None
        l_ = None
        a_ = None
        nu_ = None
        while upper - lower >= epsilon:
            tau = (lower + upper) / 2
            # Variables in CVXPY
            S_lyap = cp.Variable((3, 3), symmetric=True)
            S_pos = cp.Variable((3, 3), symmetric=True)
            P = cp.Variable((2, 2), symmetric=True) # Lyapunov parameter
            a = cp.Variable(1) # Lyapunov parameter
            l = cp.Variable(2)  # dual values : interpolation inequalities

            if not psd:
                nu = cp.Variable(1) # dual values : positivity constraints
            # CONSTRAINTS
            ### Positivity of the interpolation inequalities
            constraints = [l >= 0.]
            ### Constraints for positivity of the Lyapunov
            constraints = constraints + [a >= 0.]
            if not psd:
                constraints = constraints + [nu >= 0]
                constraints = constraints + [S_pos >> 0.]
                constraints = constraints + [S_pos[0][0] == P[0][0] + mu * nu / 2]
                constraints = constraints + [S_pos[1][0] == P[1][0]]
                constraints = constraints + [S_pos[1][1] == P[1][1]]
                constraints = constraints + [a == nu]
            else:
                constraints = constraints + [P >> 0]
            constraints = constraints + [cp.sum(cp.sum(P)) + a == 1.]
            ### Constraints on the lyapunov
            constraints = constraints + [S_lyap << 0.]
            constraints = constraints + [S_lyap[0][0] == -mu / 2 * (l[0] + l[1]) + tau * P[0][0]]
            constraints = constraints + [S_lyap[1][0] == P[0][0] - beta * P[1][0] + tau * P[1][0]]
            constraints = constraints + [S_lyap[2][0] == - alpha * P[0][1] + l[0]/2]
            constraints = constraints + [S_lyap[1][2] == - alpha * P[1][1] + a / 2]
            constraints = constraints + [S_lyap[1][1] == 2 * (P[0][1] - beta * P[1][1]) + tau * P[1][1]]
            constraints = constraints + [S_lyap[2][2] == 0]
            constraints = constraints + [tau * a == l[0] - l[1]]
            # OPTIMIZE
            prob = cp.Problem(cp.Minimize(0.), constraints)
            try:
                prob.solve(solver=cp.MOSEK)  # to improve the result: should require higher mosek precision.
                status = prob.status
            except Exception as e:
                status = 'wrong'  # if MOSEK bugs, problem is declared infeasible.
            if status == 'optimal':
                lower = tau
                P_ = P.value
                a_ = a.value
                l_ = l.value
                if not psd:
                    nu_ = nu.value
                if verbose:
                    print('feasible point: interval is now {:.6}'.format(lower), ' ,{:.6}'.format(upper))
            else:
                upper = tau
                if verbose:
                    print('infeasible point: interval is now {:.6}'.format(lower), ' ,{:.6}'.format(upper))
    else:
        P_ = P
        a_ = a
        l_ = None
        nu_ = None
        while upper - lower >= epsilon:
            tau = (lower + upper) / 2
            # Variables in CVXPY
            S_lyap = cp.Variable((3, 3), symmetric=True)
            l = cp.Variable(2)  # dual values : interpolation inequalities
            # CONSTRAINTS
            ### Positivity of the interpolation inequalities
            constraints = [l >= 0.]
            ### Constraints on the lyapunov
            constraints = constraints + [S_lyap << 0.]
            constraints = constraints + [S_lyap[0][0] == - mu / 2 * (l[0] + l[1]) + tau * P[0][0]]
            constraints = constraints + [S_lyap[1][0] == P[0][0] - beta * P[1][0] + tau * P[1][0]]
            constraints = constraints + [S_lyap[2][0] == - alpha * P[0][1] + l[0] / 2]
            constraints = constraints + [S_lyap[1][2] == - alpha * P[1][1] + a / 2]
            constraints = constraints + [S_lyap[1][1] == 2 * (P[0][1] - beta * P[1][1]) + tau * P[1][1]]
            constraints = constraints + [S_lyap[2][2] == 0]
            constraints = constraints + [tau * a == l[0] - l[1]]
            # OPTIMIZE
            prob = cp.Problem(cp.Minimize(0.), constraints)
            try:
                prob.solve(solver=cp.MOSEK)  # to improve the result: should require higher mosek precision.
                status = prob.status
            except Exception as e:
                status = 'wrong'  # if MOSEK bugs, problem is declared infeasible.
            if status == 'optimal':
                lower = tau
                l_ = l.value
                if verbose:
                    print('feasible point: interval is now {:.6}'.format(lower), ' ,{:.6}'.format(upper))
            else:
                upper = tau
                if verbose:
                    print('infeasible point: interval is now {:.6}'.format(lower), ' ,{:.6}'.format(upper))

    return tau, P_, l_, nu_, a_

def compute_convergence_primal(mu, L, alpha, beta, P, a=1):
    """
    Consider the second-order gradient flow
            d^2x/dt2 + beta * dx/dt + alpha * grad f(x(t)) = 0,
    where alpha, beta are positive parameters, and f are L-smooth mu-strongly convex functions.

    We consider quadratic Lyapunov functions
        V(x(t)) = a(f(x(t)) - f^*) + X^TPX,
        X = (x(t)-x^*, dx/dt),
    where a is a positive parameter, and P is a symmetric matrix, such that V(x(t)) is positive over the trajectory.

    This code computes the worst-case guarantee tau(L, mu, a, alpha, beta, P) such that,
        d/dt V(x(t)) <= -tau(L, mu, a, alpha, beta, P) V(x(t)),
    for all L-smooth and mu-strongly convex functions, and all ODEs generated by the second-order gradient flow.


    :param mu: strong convexity parameter
    :param L: smoothness parameter
    :param alpha: ode parameter
    :param beta: ode parameter
    :param a: Lyapunov parameter
    :param P: Lyapunov parameter
    :return:
    """
    ## PARAMETERS
    npt = 2  # optimal and initial point
    dimF = 1  # one dimension only
    dimG = 3  # (x(t) // x_dot(t) // grad f(x(t)))

    ## INITIALIZE
    FF = []
    GG = []
    YY = []
    # optimal point : equal to zero
    YY.append(np.zeros((1, dimG)))
    FF.append(np.zeros((1, dimF)))
    GG.append(np.zeros((1, dimG)))
    # initial point
    y = np.zeros((1, dimG))
    y[0][0] = 1.
    YY.append(y)
    # construction of the base
    f = np.zeros((1, dimF))
    f[0][0] = 1.
    FF.append(f)
    g = np.zeros((1, dimG))
    g[0][2] = 1.
    GG.append(g)

    # Apply the ODE and create a dimension for Y_dot
    Y_dot = np.zeros((1, dimG))
    Y_dot[0][1] = 1.
    Y_dot_dot = -GG[1] * alpha - beta * Y_dot

    X_0 = np.array([YY[1], Y_dot])
    X_1 = np.array([Y_dot, Y_dot_dot])

    # VARIABLES
    G = cp.Variable((dimG, dimG), symmetric=True)
    F = cp.Variable((dimF, 1))

    lyap = a * (FF[1] @ F[:, 0])[0] + sum([(X_0[:, 0].T @ P @ X_0[:, 0] @ G)[k, k] for k in range(dimG)])
    S = a * (Y_dot.T @ GG[1] + GG[1].T @ Y_dot) / 2 + X_1[:, 0].T @ P @ X_0[:, 0] + X_0[:, 0].T @ P @ X_1[:, 0]
    lyap_dot = sum([(S @ G)[k, k] for k in range(dimG)])

    # CONSTRAINTS
    ### Positivity of the Gram matrix
    constraints = [G >> 0.]
    ### Constraint on the previous iterate :
    constraints = constraints + [lyap == 1.]
    ### Interpolation inequalities
    for i in range(npt):
        for j in range(npt):
            if j != i:
                if (mu != 0 & L != 0):
                    Aij = np.dot((YY[i] - YY[j]).T, GG[j]) + \
                          1 / 2 / (1 - mu / L) * (1 / L * np.dot((GG[i] - GG[j]).T, GG[i] - GG[j]) +
                                                  mu * np.dot((YY[i] - YY[j]).T, YY[i] - YY[j]) -
                                                  2 * mu / L * np.dot((YY[i] - YY[j]).T, GG[i] - GG[j]))
                if (mu != 0 & L == 0):
                    Aij = np.dot((YY[i] - YY[j]).T, GG[j]) + \
                          1 / 2 * mu * np.dot((YY[i] - YY[j]).T, YY[i] - YY[j])
                if (mu == 0 & L != 0):
                    Aij = np.dot((YY[i] - YY[j]).T, GG[j]) + \
                          1 / 2 / L * np.dot((GG[i] - GG[j]).T, GG[i] - GG[j])
                if (mu == 0 & L == 0):
                    Aij = np.dot((YY[i] - YY[j]).T, GG[j])

                A = .5 * (Aij + Aij.T)
                b = FF[j] - FF[i]
                constraints += [b[0] @ F[:, 0] + sum([(A @ G)[k, k] for k in range(dimG)]) <= 0.]

    ## OPTIMIZE
    prob = cp.Problem(cp.Maximize(lyap_dot), constraints)
    prob.solve(cp.SCS)
    return prob.value, G.value, F.value






